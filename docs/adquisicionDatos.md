## 5.3 Plan de Adquisici√≥n de Datos

El plan de adquisici√≥n de datos del proyecto **‚ÄúBake IT!‚Äù** se basa en la **simulaci√≥n controlada de informaci√≥n** que representa el comportamiento real de un sistema de comercio electr√≥nico de pasteler√≠a.  
Su objetivo es garantizar la disponibilidad de un conjunto de datos **realista, coherente y voluminoso** para aplicar t√©cnicas de an√°lisis y modelado Big Data dentro del entorno del sistema.

---

### **Objetivos del Plan**
- Generar un dataset de al menos **30,000 registros simulados** representando operaciones reales del sistema.  
- Reproducir de forma cre√≠ble el comportamiento de **usuarios, ventas, productos, inventarios y rese√±as**.  
- Asegurar la **calidad, consistencia y completitud** de los datos antes del an√°lisis.  
- Permitir su integraci√≥n con herramientas de an√°lisis y visualizaci√≥n (Python, Power BI, SQL dashboards).  

---

### **Metodolog√≠a**
La generaci√≥n y adquisici√≥n de datos se realizar√° mediante procesos autom√°ticos y t√©cnicas de simulaci√≥n:

- **Python (Faker, Pandas, NumPy):** para crear registros con comportamientos realistas.  
- **Scripts SQL:** para poblar la base de datos PostgreSQL manteniendo integridad referencial.  
- **CSV y JSON:** para exportaci√≥n y an√°lisis exploratorio.  
- **Fuentes complementarias abiertas:** en caso de necesitar datos de referencia gastron√≥mica o de consumo.  

---

### **Fases del Plan (6 Semanas Totales)**

| **Semana** | **Fase / Actividad Principal** | **Descripci√≥n / Resultado Esperado** |
|-------------|--------------------------------|--------------------------------------|
| **Semana 1** | **Dise√±o del modelo de datos** | Definici√≥n de entidades, relaciones y atributos clave del sistema. |
| **Semana 2** | **Configuraci√≥n de entorno y scripts** | Implementaci√≥n de estructura en PostgreSQL y preparaci√≥n de scripts de simulaci√≥n. |
| **Semana 3** | **Generaci√≥n inicial de datos simulados** | Creaci√≥n autom√°tica de registros con Faker y carga en la base de datos. |
| **Semana 4** | **Validaci√≥n y limpieza de datos** | Detecci√≥n de inconsistencias, eliminaci√≥n de duplicados y normalizaci√≥n de datos. |
| **Semana 5** | **Integraci√≥n y an√°lisis exploratorio** | Exportaci√≥n de datos a herramientas de an√°lisis, obtenci√≥n de primeras m√©tricas. |
| **Semana 6** | **Evaluaci√≥n y documentaci√≥n final** | Revisi√≥n de la calidad, preparaci√≥n de reportes y documentaci√≥n del proceso. |

---

### **Consideraciones √âticas y de Calidad**
- Los datos son **simulados**, sin informaci√≥n personal real.  
- Se aplicar√°n **controles autom√°ticos** de calidad para validar coherencia, formato y consistencia.  
- Todo el proceso ser√° **documentado y reproducible**, asegurando trazabilidad y transparencia.  

---

### **Resumen del Cronograma**
üìÖ **Duraci√≥n total:** 6 semanas  
üß± **Fases principales:** dise√±o ‚Üí simulaci√≥n ‚Üí validaci√≥n ‚Üí an√°lisis ‚Üí documentaci√≥n  
üìä **Entregables:** dataset validado, reportes exploratorios y documentaci√≥n t√©cnica del proceso.
